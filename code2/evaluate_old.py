import torch
import torch.nn as nn
import numpy as np
from tqdm import tqdm
from torch.utils.data import DataLoader
from nuscenes_dataset import NuScenesDataset
from torchvision.models import resnet18
from PIL import Image

# =========================================================
# 1. ì˜›ë‚  ëª¨ë¸ êµ¬ì¡° ë³µì› (ResNet18 + ì €í•´ìƒë„ + Binary)
# =========================================================
class OldCamEncoder(nn.Module):
    def __init__(self, D, C):
        super(OldCamEncoder, self).__init__()
        self.D = D
        self.C = C
        self.trunk = resnet18(pretrained=False) # í‰ê°€ë§Œ í•  ê±°ë¼ pretrained ìƒê´€ì—†ìŒ
        self.trunk.fc = nn.Identity()
        self.trunk.avgpool = nn.Identity()
        self.layer1 = nn.Sequential(
            nn.Conv2d(512, D + C, kernel_size=1, padding=0)
        )

    def get_cam_feats(self, x):
        x = self.trunk.conv1(x)
        x = self.trunk.bn1(x)
        x = self.trunk.relu(x)
        x = self.trunk.maxpool(x)
        x = self.trunk.layer1(x)
        x = self.trunk.layer2(x)
        x = self.trunk.layer3(x)
        x = self.trunk.layer4(x) 
        x = self.layer1(x)
        return x 

    def forward(self, x):
        x = self.get_cam_feats(x)
        depth_logits = x[:, :self.D]
        context = x[:, self.D:]
        depth_probs = depth_logits.softmax(dim=1)
        return depth_probs, context

class OldLSSModel(nn.Module):
    def __init__(self, device):
        super(OldLSSModel, self).__init__()
        # ì˜›ë‚  ì„¤ì • (ResNet18, 704x256, 1ì±„ë„ ì¶œë ¥)
        self.xbound = [-50, 50, 0.5]
        self.ybound = [-50, 50, 0.5]
        self.zbound = [-10, 10, 20] # ë†’ì´ 1ê°œ ì¸µìœ¼ë¡œ ê°€ì • (Binary)
        self.dbound = [4, 45, 1]
        self.C = 64
        
        self.nx = int((self.xbound[1] - self.xbound[0]) / self.xbound[2]) # 200
        self.ny = int((self.ybound[1] - self.ybound[0]) / self.ybound[2]) # 200
        self.D = int((self.dbound[1] - self.dbound[0]) / self.dbound[2])  # 41
        
        # Frustum (8x22)
        H, W = 8, 22
        ds = torch.arange(self.dbound[0], self.dbound[1], self.dbound[2]).view(-1, 1, 1).expand(-1, H, W)
        D = ds.shape[0]
        xs = torch.linspace(0, 703, W).view(1, 1, W).expand(D, H, W)
        ys = torch.linspace(0, 255, H).view(1, H, 1).expand(D, H, W)
        self.frustum = nn.Parameter(torch.stack((xs, ys, ds), -1), requires_grad=False)
        
        self.cam_encoder = OldCamEncoder(D=self.D, C=self.C)
        
        self.bev_compressor = nn.Sequential(
            nn.Conv2d(self.C, self.C, kernel_size=3, padding=1),
            nn.BatchNorm2d(self.C),
            nn.ReLU(inplace=True),
        )
        
        # Decoder ì¶œë ¥ 1ì±„ë„ (Binary)
        self.decoder = nn.Conv2d(self.C, 1, kernel_size=1)
        self.device = device

    def get_geometry(self, rots, trans, intrinsics):
        B = rots.shape[0]
        points = self.frustum.unsqueeze(0).repeat(B, 1, 1, 1, 1)
        points = points.view(B, -1, 3)
        points_d = points[:, :, 2]
        points[:, :, 0] = (points[:, :, 0] - intrinsics[:, 0, 2].unsqueeze(1)) * points_d / intrinsics[:, 0, 0].unsqueeze(1)
        points[:, :, 1] = (points[:, :, 1] - intrinsics[:, 1, 2].unsqueeze(1)) * points_d / intrinsics[:, 1, 1].unsqueeze(1)
        points = torch.bmm(rots, points.permute(0, 2, 1)).permute(0, 2, 1) + trans.unsqueeze(1)
        return points.view(B, self.D, 8, 22, 3)

    def voxel_pooling(self, geom_feats, x):
        B, D, H, W, _ = geom_feats.shape
        geom_feats = geom_feats.reshape(-1, 3)
        x = x.permute(0, 1, 3, 4, 2).reshape(-1, x.shape[2])
        
        keep = ((geom_feats[:, 0] >= self.xbound[0]) & (geom_feats[:, 0] < self.xbound[1]) &
                (geom_feats[:, 1] >= self.ybound[0]) & (geom_feats[:, 1] < self.ybound[1]))
        geom_feats = geom_feats[keep]
        x = x[keep]
        
        # Batch Indices (ê°„ì†Œí™”)
        # ë°°ì¹˜ 1ê°œì”©ë§Œ ì²˜ë¦¬í•œë‹¤ê³  ê°€ì •í•˜ë©´ ê°„ë‹¨í•¨
        coords = ((geom_feats - torch.tensor([self.xbound[0], self.ybound[0], self.zbound[0]]).to(x.device)) / 
                  torch.tensor([self.xbound[2], self.ybound[2], self.zbound[2]]).to(x.device)).long()
        
        final_bev = torch.zeros((self.nx, self.ny, self.C), device=x.device)
        final_bev.index_put_((coords[:, 0], coords[:, 1]), x, accumulate=True)
        return final_bev.permute(2, 0, 1).unsqueeze(0)

    def forward(self, imgs, rots, trans, intrinsics):
        # ì´ë¯¸ì§€ í¬ê¸° ê°•ì œ ì¡°ì ˆ (1056x384 -> 704x256)
        # êµ¬í˜• ëª¨ë¸ì€ ì‘ì€ ì´ë¯¸ì§€ë¥¼ ì›í•˜ë¯€ë¡œ ë¦¬ì‚¬ì´ì¦ˆ í•„ìš”
        # (í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” Datasetì—ì„œ ì´ë¯¸ 704x256ìœ¼ë¡œ ì¤„ì—¬ì„œ ì˜¨ë‹¤ê³  ê°€ì •í•˜ê±°ë‚˜, 
        #  ëª¨ë¸ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬í•´ì•¼ í•¨. ë³´í†µ Dataset ì„¤ì •ì„ ë”°ë¦„)
        
        B, N, _, H, W = imgs.shape
        imgs = imgs.view(B * N, 3, H, W)
        rots = rots.view(B * N, 3, 3)
        trans = trans.view(B * N, 3)
        intrinsics = intrinsics.view(B * N, 3, 3)

        depth_probs, context = self.cam_encoder(imgs)
        geom = self.get_geometry(rots, trans, intrinsics)
        
        context = context.unsqueeze(1)
        depth_probs = depth_probs.unsqueeze(2)
        frustum_features = context * depth_probs 
        
        geom = geom.reshape(B, -1, 8, 22, 3)
        frustum_features = frustum_features.reshape(B, -1, self.C, 8, 22)

        # Splat (Batch 1ì¼ ë•Œë§Œ ì‘ë™í•˜ëŠ” ê°„ì´ ë²„ì „)
        bev_map = self.voxel_pooling(geom, frustum_features)
        bev_map = self.bev_compressor(bev_map)
        out = self.decoder(bev_map)
        return out

# =========================================================
# 2. ì‹¤í–‰ ì½”ë“œ
# =========================================================
def evaluate_old_model():
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"ğŸš€ NVIDIA GPU (CUDA) ê°€ì† í™œì„±í™”ë¨! ì‚¬ìš© ì¥ì¹˜: {torch.cuda.get_device_name(0)}")
        
    # 2ìˆœìœ„: MPS (Apple Silicon Mac) í™•ì¸
    elif torch.backends.mps.is_available():
        device = torch.device("mps")
        print("ğŸ Apple M1/M2/M3 MPS ê°€ì† í™œì„±í™”ë¨!")
        
    # 3ìˆœìœ„: CPU (ëª¨ë‘ ì—†ì„ ê²½ìš°)
    else:
        device = torch.device("cpu")
        print("âš ï¸ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    
    # [ì„¤ì •] êµ¬ë²„ì „ ëª¨ë¸ íŒŒì¼ëª…
    # (ì•„ê¹Œ ì—ëŸ¬ ë‚¬ë˜ ê·¸ íŒŒì¼ ì´ë¦„ì„ ì—¬ê¸°ì— ì ìœ¼ì„¸ìš”)
    model_path = "best_lss_multicam.pth" 

    # 1. ëª¨ë¸ ì¤€ë¹„
    model = OldLSSModel(device).to(device)
    
    try:
        # strict=Falseë¡œ í•˜ë©´ ë¶ˆí•„ìš”í•œ í‚¤(running_mean ë“±) ë¬´ì‹œí•˜ê³  ë¡œë“œ
        model.load_state_dict(torch.load(model_path, map_location=device), strict=False)
        print(f"âœ… êµ¬ë²„ì „ ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_path}")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    model.eval()

    # 2. ë°ì´í„°ì…‹ (í•´ìƒë„ 704x256ìœ¼ë¡œ ê°•ì œ ì„¤ì • í•„ìš”)
    # í˜„ì¬ nuscenes_dataset.pyê°€ ê³ í•´ìƒë„(1056x384)ë¡œ ë˜ì–´ ìˆë‹¤ë©´, 
    # ì¼ì‹œì ìœ¼ë¡œ 704x256ìœ¼ë¡œ ë™ì‘í•˜ë„ë¡ í•˜ëŠ” ê²ƒì´ ì¢‹ì§€ë§Œ,
    # ì—¬ê¸°ì„œëŠ” ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³  Datasetì„ ë¶ˆëŸ¬ì˜¨ ë’¤, ì´ë¯¸ì§€ Resizeë¥¼ ë‹¤ì‹œ í•´ì£¼ëŠ” ë°©ì‹ ì‚¬ìš©
    
    dataset = NuScenesDataset(dataroot='../data/sets/nuscenesmini', is_train=False) # Validation set
    loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)

    print("ğŸš€ êµ¬ë²„ì „ ëª¨ë¸ ì •í™•ë„ ì¸¡ì • ì‹œì‘...")
    
    total_iou = 0
    count = 0
    
    with torch.no_grad():
        for i, (imgs, intrinsics, sensor2ego, gt_bev) in enumerate(tqdm(loader)):
            # [ì¤‘ìš”] ì´ë¯¸ì§€ë¥¼ 704x256ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ëª¨ë¸ì´ ì˜›ë‚  ê±°ë¼)
            imgs = torch.nn.functional.interpolate(imgs.view(-1, 3, 384, 1056), size=(256, 704), mode='bilinear')
            imgs = imgs.view(1, 6, 3, 256, 704)
            
            # Intrinsics ìŠ¤ì¼€ì¼ ë³´ì • (384 -> 256)
            scale_x = 704 / 1056
            scale_y = 256 / 384
            intrinsics = intrinsics.clone()
            intrinsics[..., 0] *= scale_x
            intrinsics[..., 1] *= scale_y

            imgs = imgs.to(device)
            intrinsics = intrinsics.float().to(device)
            rots = sensor2ego[:, :, :3, :3].float().to(device)
            trans = sensor2ego[:, :, :3, 3].float().to(device)
            gt_bev = gt_bev.to(device)
            
            # ì˜ˆì¸¡
            preds = model(imgs, rots, trans, intrinsics) # (1, 1, 200, 200)
            preds_prob = torch.sigmoid(preds)
            
            # GT ì²˜ë¦¬ (Binary)
            # Semantic GT (0,1,2,3) -> Binary GT (0,1)
            gt_map = (torch.max(gt_bev[0], dim=0)[0] > 0).float().cpu().numpy()
            pred_map = (preds_prob[0, 0] > 0.4).cpu().numpy().astype(float)
            
            # IoU ê³„ì‚°
            intersection = (pred_map * gt_map).sum()
            union = (pred_map + gt_map).sum() - intersection
            
            if union > 0:
                total_iou += intersection / union
                count += 1
                
    print("\n" + "="*40)
    print(f"ğŸ“Š êµ¬ë²„ì „ ëª¨ë¸(Binary) ìµœì¢… ê²°ê³¼")
    print(f" - í‰ê·  IoU: {total_iou / count * 100:.2f}%")
    print("="*40)

if __name__ == "__main__":
    evaluate_old_model()